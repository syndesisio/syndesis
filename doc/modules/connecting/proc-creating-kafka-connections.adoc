// This module is included in the following assemblies:
// as_connecting-to-kafka.adoc

[id='creating-kafka-connections_{context}']
= Creating a connection to a Kafka broker

In an integration, to subscribe for data from a Kafka topic
or publish data to a Kafka topic,
create a connection to Kafka and then add that connection to an
integration.

.Prerequisite

* If you want to use Transport Layer Security (TLS) to encrypt your data, you have the Kafka broker’s PEM certificate text. Typically, you obtain the broker certificate text from your Kafka server administrator.

.Procedure

. In {prodname}, in the left panel, click *Connections* to
display any available connections.
. Click *Create Connection* to display
connectors.
. Click the *Kafka Message Broker* connector.
. In the *Kafka broker URIs* field, select the broker that you want
this connection to access, or enter a comma separated list
of Kafka broker URIs. Each URI should be in the form `host:port`.
. For the *Security Protocol* field, select one of the following options:
* If you want to encrypt your data to protect it in transit, select *TLS* (Transport Layer Security).
* If you want to authenticate with SASL and encrypt your data with SSL, select *SASL_SSL*.
* If you do not want to encrypt your data, select *Plain* and then skip to Step 7.
. If you selected *SASL_SSL* as the *Security Protocol*, then you are required to choose between two options to setup the credentials:
* If you want to use *PLAIN* as the *SASL Mechanism* you must set the *Username* and *Password* fields.
* If you want to use *OAUTHBEARER* as the *SASL Mechanism* you must set the following fields:
+
*Username* with the OAuth Client Id.
*Password* with the OAUth Client Secret.
*SASL Login Callback Handler Class* you can use any callback handler class from kafka-clients 2.5 version or kafka-oauth-client from strimzi project. To connect to Red Hat Managed Kafka, you can set as `io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler`.
*OAuth Token Endpoint URI* with the value provided by your provider.
. If you selected *TLS* in Step 5, then in the *Broker certificate* field, paste the Kafka broker’s PEM certificate text.

. Optional. Click *Add* to specify `key:value` pairs to configure Kafka producer and consumer options.
+
For example, if you want a new integration to be able to consume old messages from a topic, change the `auto.offset.reset` value from the default (`latest`) to `earliest` by typing  *auto.offset.reset* for the *Key* field and *earliest* for the *Value* field.
+
For details about Kafka producer configuration options, go to https://kafka.apache.org/documentation/#producerconfigs
+
For details about Kafka consumer configuration options, go to https://kafka.apache.org/documentation/#consumerconfigs
+
*Note:* If you add configuration attributes, {prodname} does not include them as part of its validation process in the next step.
. Click *Validate*. {prodname} immediately tries to validate the
connection and displays a message that indicates whether
validation is successful. If validation fails, revise the input
parameter and try again.
. If validation is successful, click *Next*.
. In the *Name* field, enter your choice of a name that
helps you distinguish this connection from any other connections.
For example, you might type `Kafka West`.
. In the *Description* field, optionally enter any information that
is helpful to know about this connection.
. Click *Save* to see that the connection you
created is now available. If you
entered the example name, you would
see that *Kafka West* appears as a connection that you can
choose to add to an integration.
